{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcc8d50-1700-4486-9f57-d5897f13c428",
   "metadata": {},
   "source": [
    "## BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb4f0df-d42d-46dd-a2e1-70baf975eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/shola/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/shola/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trending terms:\n",
      "pla: 2.66× growth (0.66→2.41 per 100 tweets 2016→2023)\n",
      "rocket: 2.63× growth (0.77→2.79 per 100 tweets 2013→2023)\n",
      "material: 1.99× growth (1.29→3.88 per 100 tweets 2012→2023)\n",
      "additive: 1.84× growth (3.25→9.22 per 100 tweets 2012→2023)\n",
      "additive manufacturing: 1.79× growth (3.10→8.66 per 100 tweets 2012→2023)\n",
      "engineering: 1.57× growth (0.66→1.71 per 100 tweets 2016→2023)\n",
      "filament: 1.40× growth (1.15→2.76 per 100 tweets 2014→2023)\n",
      "models: 1.33× growth (2.18→5.07 per 100 tweets 2012→2023)\n",
      "resin: 1.19× growth (1.07→2.35 per 100 tweets 2019→2023)\n",
      "research: 1.18× growth (1.08→2.35 per 100 tweets 2012→2023)\n",
      "printing 3d printing: 1.13× growth (0.84→1.78 per 100 tweets 2012→2023)\n",
      "parts: 1.09× growth (2.51→5.25 per 100 tweets 2012→2023)\n",
      "market: 1.09× growth (0.81→1.70 per 100 tweets 2013→2023)\n",
      "construction: 1.04× growth (0.74→1.52 per 100 tweets 2017→2023)\n",
      "ai: 1.00× growth (1.05→2.10 per 100 tweets 2018→2023)\n",
      "manufacturing: 0.99× growth (5.76→11.45 per 100 tweets 2012→2023)\n",
      "innovation: 0.86× growth (1.09→2.03 per 100 tweets 2012→2023)\n",
      "process: 0.86× growth (0.69→1.29 per 100 tweets 2017→2023)\n",
      "global: 0.85× growth (0.73→1.36 per 100 tweets 2017→2019)\n",
      "custom: 0.85× growth (1.02→1.89 per 100 tweets 2012→2023)\n",
      "industrial: 0.77× growth (0.72→1.27 per 100 tweets 2012→2019)\n",
      "laser: 0.76× growth (0.70→1.24 per 100 tweets 2016→2023)\n",
      "metal: 0.75× growth (1.87→3.26 per 100 tweets 2013→2023)\n",
      "3dp: 0.72× growth (0.68→1.17 per 100 tweets 2013→2023)\n",
      "university: 0.69× growth (0.77→1.30 per 100 tweets 2017→2020)\n",
      "school: 0.69× growth (0.70→1.18 per 100 tweets 2016→2020)\n",
      "lab: 0.67× growth (0.71→1.18 per 100 tweets 2012→2023)\n",
      "software: 0.66× growth (0.65→1.09 per 100 tweets 2016→2022)\n",
      "students: 0.64× growth (0.98→1.60 per 100 tweets 2014→2023)\n",
      "metal 3d: 0.62× growth (0.72→1.17 per 100 tweets 2016→2023)\n",
      "stem: 0.60× growth (0.74→1.18 per 100 tweets 2016→2019)\n",
      "printing technology: 0.60× growth (0.92→1.48 per 100 tweets 2012→2023)\n",
      "3d printing technology: 0.59× growth (0.89→1.42 per 100 tweets 2012→2023)\n",
      "using 3d printing: 0.59× growth (0.78→1.24 per 100 tweets 2014→2020)\n",
      "industry: 0.59× growth (1.50→2.38 per 100 tweets 2012→2023)\n",
      "fashion: 0.58× growth (0.71→1.12 per 100 tweets 2012→2019)\n",
      "space: 0.58× growth (1.68→2.65 per 100 tweets 2013→2023)\n",
      "3d printing parts: 0.57× growth (0.66→1.03 per 100 tweets 2015→2022)\n",
      "printing parts: 0.57× growth (0.67→1.05 per 100 tweets 2015→2022)\n",
      "maker: 0.55× growth (0.90→1.40 per 100 tweets 2012→2018)\n",
      "making: 0.55× growth (1.25→1.94 per 100 tweets 2012→2023)\n",
      "human: 0.54× growth (1.05→1.62 per 100 tweets 2013→2019)\n",
      "join: 0.53× growth (1.05→1.62 per 100 tweets 2018→2023)\n",
      "kit: 0.53× growth (0.67→1.03 per 100 tweets 2016→2022)\n",
      "top: 0.53× growth (0.78→1.19 per 100 tweets 2014→2022)\n",
      "diy: 0.50× growth (0.90→1.34 per 100 tweets 2012→2020)\n",
      "prints: 0.49× growth (0.71→1.05 per 100 tweets 2012→2023)\n",
      "manufacturing 3d: 0.49× growth (1.06→1.58 per 100 tweets 2019→2023)\n",
      "large: 0.48× growth (0.68→1.01 per 100 tweets 2017→2022)\n",
      "anyone: 0.48× growth (0.81→1.20 per 100 tweets 2012→2023)\n",
      "machine: 0.47× growth (0.81→1.20 per 100 tweets 2014→2023)\n",
      "manufacturing 3d printing: 0.44× growth (1.04→1.50 per 100 tweets 2022→2023)\n",
      "little: 0.44× growth (0.88→1.26 per 100 tweets 2012→2023)\n",
      "3d printing 3d: 0.43× growth (2.10→3.01 per 100 tweets 2012→2023)\n",
      "production: 0.43× growth (1.02→1.45 per 100 tweets 2017→2023)\n",
      "digital: 0.43× growth (0.98→1.39 per 100 tweets 2012→2023)\n",
      "game: 0.41× growth (1.07→1.51 per 100 tweets 2021→2023)\n",
      "science: 0.41× growth (0.84→1.19 per 100 tweets 2012→2019)\n",
      "printing 3d: 0.41× growth (2.23→3.13 per 100 tweets 2012→2023)\n",
      "via 3d printing: 0.39× growth (1.07→1.49 per 100 tweets 2013→2015)\n",
      "via 3d: 0.37× growth (1.11→1.52 per 100 tweets 2013→2015)\n",
      "system: 0.37× growth (0.79→1.07 per 100 tweets 2017→2019)\n",
      "looking: 0.36× growth (0.99→1.34 per 100 tweets 2018→2023)\n",
      "art: 0.36× growth (1.11→1.51 per 100 tweets 2012→2023)\n",
      "via youtube: 0.36× growth (0.77→1.05 per 100 tweets 2016→2023)\n",
      "medical: 0.36× growth (0.78→1.06 per 100 tweets 2014→2022)\n",
      "technology: 0.36× growth (3.63→4.93 per 100 tweets 2012→2023)\n",
      "new 3d printing: 0.35× growth (0.74→1.00 per 100 tweets 2012→2017)\n",
      "plastic: 0.34× growth (0.95→1.28 per 100 tweets 2012→2022)\n",
      "stratasys: 0.34× growth (0.87→1.17 per 100 tweets 2012→2019)\n",
      "fun: 0.33× growth (1.02→1.36 per 100 tweets 2019→2023)\n",
      "printing additive manufacturing: 0.32× growth (1.04→1.37 per 100 tweets 2018→2022)\n",
      "en: 0.32× growth (0.82→1.09 per 100 tweets 2012→2022)\n",
      "created: 0.32× growth (0.81→1.08 per 100 tweets 2012→2019)\n",
      "company: 0.31× growth (1.10→1.44 per 100 tweets 2012→2023)\n",
      "3d printing additive: 0.29× growth (1.06→1.37 per 100 tweets 2018→2022)\n",
      "house: 0.29× growth (0.91→1.17 per 100 tweets 2012→2023)\n",
      "printing additive: 0.29× growth (1.08→1.39 per 100 tweets 2018→2022)\n",
      "printer 3d printing: 0.29× growth (0.80→1.03 per 100 tweets 2012→2019)\n",
      "business: 0.28× growth (0.83→1.07 per 100 tweets 2012→2023)\n",
      "much: 0.27× growth (1.07→1.36 per 100 tweets 2019→2023)\n",
      "size: 0.27× growth (1.01→1.28 per 100 tweets 2018→2022)\n",
      "desktop: 0.27× growth (0.93→1.18 per 100 tweets 2012→2017)\n",
      "3d printer 3d: 0.26× growth (1.07→1.36 per 100 tweets 2012→2019)\n",
      "printed: 0.25× growth (1.87→2.34 per 100 tweets 2012→2023)\n",
      "design: 0.24× growth (3.70→4.58 per 100 tweets 2012→2023)\n",
      "available: 0.24× growth (0.97→1.20 per 100 tweets 2018→2023)\n",
      "well: 0.22× growth (1.12→1.37 per 100 tweets 2019→2023)\n",
      "robotics: 0.22× growth (1.76→2.14 per 100 tweets 2012→2023)\n",
      "great: 0.21× growth (1.44→1.75 per 100 tweets 2012→2023)\n",
      "printing: 0.19× growth (86.05→102.77 per 100 tweets 2012→2023)\n",
      "3d printing: 0.19× growth (83.45→99.64 per 100 tweets 2012→2023)\n",
      "3d systems: 0.18× growth (0.76→0.90 per 100 tweets 2012→2014)\n",
      "learning: 0.17× growth (1.00→1.18 per 100 tweets 2018→2019)\n",
      "story: 0.17× growth (0.71→0.83 per 100 tweets 2013→2015)\n",
      "hand: 0.17× growth (0.91→1.06 per 100 tweets 2013→2018)\n",
      "mini: 0.17× growth (0.74→0.87 per 100 tweets 2015→2017)\n",
      "create: 0.16× growth (1.67→1.94 per 100 tweets 2012→2023)\n",
      "ge: 0.16× growth (0.63→0.72 per 100 tweets 2016→2017)\n",
      "printing 3d printer: 0.15× growth (1.09→1.25 per 100 tweets 2012→2022)\n",
      "using 3d: 0.14× growth (1.15→1.31 per 100 tweets 2012→2023)\n",
      "big: 0.13× growth (1.11→1.24 per 100 tweets 2012→2023)\n",
      "print: 0.12× growth (3.79→4.23 per 100 tweets 2012→2023)\n",
      "youtube video: 0.12× growth (0.84→0.94 per 100 tweets 2017→2018)\n",
      "creality: 0.12× growth (1.22→1.36 per 100 tweets 2022→2023)\n",
      "light: 0.11× growth (0.97→1.08 per 100 tweets 2018→2019)\n",
      "car: 0.11× growth (0.96→1.06 per 100 tweets 2012→2018)\n",
      "homes: 0.10× growth (0.94→1.03 per 100 tweets 2018→2022)\n",
      "pro: 0.08× growth (1.15→1.24 per 100 tweets 2020→2023)\n",
      "systems: 0.08× growth (0.96→1.03 per 100 tweets 2012→2019)\n",
      "scale: 0.08× growth (1.08→1.16 per 100 tweets 2021→2023)\n",
      "industry 3d printing: 0.08× growth (0.71→0.77 per 100 tweets 2014→2015)\n",
      "printing industry 3d: 0.07× growth (0.67→0.72 per 100 tweets 2014→2015)\n",
      "uses: 0.07× growth (0.85→0.92 per 100 tweets 2012→2018)\n",
      "files: 0.06× growth (1.01→1.07 per 100 tweets 2021→2023)\n",
      "prototyping: 0.06× growth (1.05→1.11 per 100 tweets 2018→2022)\n",
      "3d printing pen: 0.06× growth (0.78→0.82 per 100 tweets 2013→2016)\n",
      "printing pen: 0.05× growth (0.81→0.84 per 100 tweets 2013→2016)\n",
      "industry 3d: 0.04× growth (0.75→0.78 per 100 tweets 2014→2015)\n",
      "3d: 0.04× growth (125.99→130.94 per 100 tweets 2012→2023)\n",
      "world 3d: 0.04× growth (1.02→1.06 per 100 tweets 2012→2023)\n",
      "future 3d: 0.03× growth (0.70→0.72 per 100 tweets 2012→2013)\n",
      "use 3d printing: 0.03× growth (0.75→0.77 per 100 tweets 2012→2017)\n",
      "still: 0.03× growth (1.24→1.27 per 100 tweets 2020→2023)\n",
      "3d printing car: 0.02× growth (1.03→1.05 per 100 tweets 2014→2015)\n",
      "printing car: 0.02× growth (1.04→1.06 per 100 tweets 2014→2015)\n",
      "metal 3d printing: 0.02× growth (0.95→0.97 per 100 tweets 2017→2018)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# def normalize_variants(df):\n",
    "#     \"\"\"\n",
    "#     Standardize only the 3D-printing and additive-manufacturing variants\n",
    "#     in df['Normalized Text'], so downstream vectorization sees the\n",
    "#     unified phrases.\n",
    "#     \"\"\"\n",
    "#     fixes = {\n",
    "\n",
    "#     # research/researchers → research\n",
    "#     r'\\bresearchers?\\b':'research',\n",
    "#     # model/models → models\n",
    "#     r'\\bmodels?\\b':'models',\n",
    "#     # part/parts → parts\n",
    "#     r'\\bparts?\\b':'parts',\n",
    "        \n",
    "#     # gun / guns → \"guns\"\n",
    "#     r'\\bgun(?:s)?\\b':'guns',\n",
    "    \n",
    "#     # 3d printing variants → \"3d printing\"\n",
    "#     r'\\b3d[-\\s]*print(?:ing|ed|ted)?\\b':'3d printing',\n",
    "#     r'\\b3dprinting\\b':'3d printing',\n",
    "\n",
    "#     # additive manufacturing variants → \"additive manufacturing\"\n",
    "#     # match “additive manufacture” + optional “d” or “ing”\n",
    "#     r'\\badditive[-\\s]*manufactur(?:e|ed|ing)?\\b':'additive manufacturing',\n",
    "#     # catch concatenated form “additivemanufacturing”\n",
    "#     r'\\badditivemanufactur(?:e|ing)\\b':'additive manufacturing',\n",
    "#     # any other small misspelling\n",
    "#     r'\\baddive[-\\s]*manufactu(?:ed|ring)?\\b':'additive manufacturing',\n",
    "\n",
    "#     # materials/material → material\n",
    "#     r'\\bmaterials?\\b':'material',\n",
    "\n",
    "#     r'\\b3d[-\\s]*printing technology\\b':'3d printing technology',\n",
    "#     r'\\bprinting technology\\b':'3d printing technology',\n",
    "        \n",
    "#     # **ADD THESE LINES**  \n",
    "#     r'\\b3d[-\\s]*printer(?:s)?\\b':'3d printer',\n",
    "#     r'\\b3dprinter(?:s)?\\b':'3d printer',\n",
    "#     r'\\bprinters?\\b':'printer',\n",
    "#     }\n",
    "\n",
    "#      fixes.update({\n",
    "#       # use/used\n",
    "#       r'\\bused\\b':                     'use',\n",
    "#       # printing guns → 3d printing guns\n",
    "#       r'\\bprinting guns\\b':            '3d printing guns',\n",
    "#       # first 3d / first 3d printing\n",
    "#       r'\\bfirst\\s+3d\\b':               '3d',\n",
    "#       r'\\bfirst\\s+3d\\s+printing\\b':    '3d printing',\n",
    "#       # 3d print-industry\n",
    "#       r'\\b3dprintindustry\\b':          '3d printing industry',\n",
    "#       r'\\b3d[-\\s]*print(?:ing)?\\s+industry\\b': '3d printing industry',\n",
    "#     })\n",
    "\n",
    "#     text = df['Normalized Text'].fillna('')\n",
    "#     for pat, repl in fixes.items():\n",
    "#         text = text.str.replace(pat, repl, regex=True, flags=re.IGNORECASE)\n",
    "#     df = df.copy()\n",
    "#     df['Normalized Text'] = text\n",
    "#     return df\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def normalize_variants(df):\n",
    "    \"\"\"\n",
    "    Standardize variants in df['Normalized Text'] so that downstream\n",
    "    n-grams come out unified.\n",
    "    \"\"\"\n",
    "    fixes = {\n",
    "        # research/researchers → research\n",
    "        r'\\bresearch(?:ers)?\\b':                   'research',\n",
    "\n",
    "        # model/models → models\n",
    "        r'\\bmodels?\\b':                           'models',\n",
    "        # part/parts → parts\n",
    "        r'\\bparts?\\b':                            'parts',\n",
    "\n",
    "        # gun/guns → guns\n",
    "        r'\\bgun(?:s)?\\b':                         'guns',\n",
    "\n",
    "        # 3d printing variants → \"3d printing\"\n",
    "        r'\\b3d[-\\s]*print(?:ing|ed|ted)?\\b':      '3d printing',\n",
    "        r'\\b3dprinting\\b':                        '3d printing',\n",
    "\n",
    "        # 3d printer variants → \"3d printer\"\n",
    "        r'\\b3d[-\\s]*printer(?:s)?\\b':             '3d printer',\n",
    "        r'\\b3dprinter(?:s)?\\b':                   '3d printer',\n",
    "        r'\\bprinters?\\b':                         'printer',\n",
    "\n",
    "        # additive manufacturing variants → \"additive manufacturing\"\n",
    "        r'\\badditive[-\\s]*manufactur(?:e|ed|ing)?\\b': 'additive manufacturing',\n",
    "        r'\\badditivemanufactur(?:e|ing)\\b':           'additive manufacturing',\n",
    "        r'\\baddive[-\\s]*manufactu(?:ed|ring)?\\b':      'additive manufacturing',\n",
    "\n",
    "        # materials/material → material\n",
    "        r'\\bmaterials?\\b':                         'material',\n",
    "\n",
    "        # use/used → use\n",
    "        r'\\bused\\b':                               'use',\n",
    "\n",
    "        # printing guns → 3d printing guns\n",
    "        #r'\\bprinting guns\\b':                      '3d printing guns',\n",
    "\n",
    "        # first 3d / first 3d printing → 3d( printing)\n",
    "        r'\\bfirst\\s+3d\\s+printing\\b':              '3d printing',\n",
    "        r'\\bfirst\\s+3d\\b':                         '3d',\n",
    "\n",
    "        # 3dprintindustry → 3d printing industry\n",
    "        r'\\b3dprintindustry\\b':                    '3d printing industry',\n",
    "        r'\\b3d[-\\s]*print(?:ing)?\\s+industry\\b':   '3d printing industry',\n",
    "\n",
    "        # robot/robots → robotics\n",
    "        r'\\brobots?\\b': 'robotics',\n",
    "    }\n",
    "\n",
    "    # Apply each regex replacement, case-insensitive\n",
    "    text = df['Normalized Text'].fillna('')\n",
    "    for pattern, replacement in fixes.items():\n",
    "        text = text.str.replace(pattern, replacement, regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['Normalized Text'] = text\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "def extract_year_ngrams(df, custom_stopwords, n_range=(1, 3), min_df=2, top_n=50):\n",
    "    texts = df['Normalized Text'].fillna('').tolist()\n",
    "    if not texts:\n",
    "        return pd.DataFrame(columns=['ngram', 'frequency'])\n",
    "    vec = CountVectorizer(\n",
    "        ngram_range=n_range,\n",
    "        stop_words=list(custom_stopwords),\n",
    "        min_df=min_df,\n",
    "        token_pattern=r'\\b[a-zA-Z0-9_]+\\b'\n",
    "    )\n",
    "    X = vec.fit_transform(texts)\n",
    "    names = vec.get_feature_names_out()\n",
    "    counts = X.sum(axis=0).A1\n",
    "    df_ngrams = pd.DataFrame({'ngram': names, 'frequency': counts})\n",
    "    return df_ngrams.sort_values('frequency', ascending=False).head(top_n)\n",
    "\n",
    "def find_trending_terms(all_ngrams_df, min_years=2, top_n=15):\n",
    "    # work on a copy so the original stays intact\n",
    "    df = all_ngrams_df.copy()\n",
    "\n",
    "    # remove unwanted terms and pure numbers\n",
    "    remove_terms = {\n",
    "        'help', 'get', 'twitter', 'like', 'one', 'using', 'see',\n",
    "        'youtube', 'today', 'check', 'us', 'made', 'first', 'time', 'learn', 'de', 'want', 'first',\n",
    "        'week', 'know', 'good', 'year', 'day', 'need', 'project', 'would','high','free', 'think',\n",
    "        'utm_medium', 'utm_source', 'igshid',\n",
    "        'post','way','also', 'thanks',\n",
    "        'something','coming','utm_source twitter','years',\n",
    "        'two', 'look', 'going', 'latest', 'got', 'take', 'utm_campaign', 'x', \n",
    "        'come', 'another', 'hours', 'really', 'utm_source twitter', 'youtube video'\n",
    "\n",
    "        # generic filler / low-value\n",
    "        'work', 'heart', 'read', 'people', 'set', 'based', 'designed',\n",
    "        'social', 'building', 'go', 'best', 'full', 'team', 'life',\n",
    "        'ready', 'buy', 'live', 'watch', 'use', 'working', 'things',\n",
    "        'love', 'stuff', 'thing', 'back', 'even', 'many', 'make',\n",
    "        'build', 'find', 'start', 'last', 'ever', 'test', 'share',\n",
    "        'new', 'r', 'e', 'w', 'hp', 'drone', 'app'\n",
    "\n",
    "        \n",
    "    }\n",
    "\n",
    "    remove_terms.update({\n",
    "    'rocket', 'ai', 'engineering', 'fashion', 'stem',\n",
    "    'university', 'school', 'lab', 'students',\n",
    "    'go', 'market', 'global', 'construction', 'process', 'innovation',\n",
    "    'maker', 'making',\n",
    "    'fun', 'love', 'life', 'watch', 'read'\n",
    "})\n",
    "    mask = (~df['ngram'].isin(remove_terms)) & (~df['ngram'].str.isdigit())\n",
    "    df = df[mask]\n",
    "\n",
    "    # keep only terms that appear in at least min_years distinct years\n",
    "    common = df.groupby('ngram').filter(\n",
    "        lambda grp: grp['year'].nunique() >= min_years\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for term, grp in common.groupby('ngram'):\n",
    "        grp = grp.sort_values('year')\n",
    "        first, last = grp.iloc[0], grp.iloc[-1]\n",
    "        abs_ch = last['freq_per_100_tweets'] - first['freq_per_100_tweets']\n",
    "        if abs_ch <= 0:\n",
    "            continue\n",
    "        if first['freq_per_100_tweets'] > 0:\n",
    "            rel_ch = abs_ch / first['freq_per_100_tweets']\n",
    "        else:\n",
    "            rel_ch = float('inf')\n",
    "        records.append({\n",
    "            'term':       term,\n",
    "            'first_year': int(first['year']),\n",
    "            'last_year':  int(last['year']),\n",
    "            'first_freq': first['freq_per_100_tweets'],\n",
    "            'last_freq':  last['freq_per_100_tweets'],\n",
    "            'abs_change': abs_ch,\n",
    "            'rel_change': rel_ch,\n",
    "            'word_count': int(first['word_count'])\n",
    "        })\n",
    "\n",
    "    df_trend = pd.DataFrame(records)\n",
    "    return df_trend.sort_values('rel_change', ascending=False).head(top_n)\n",
    "\n",
    "def main():\n",
    "    # 1) Setup\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    stops = set(stopwords.words('english'))\n",
    "    twitter_stops = {'rt','amp','http','https','co','t','s','m','re','ve','ll','d'}\n",
    "    custom_stops = stops.union(twitter_stops)\n",
    "\n",
    "    # 2) Read raw tweets\n",
    "    df = pd.read_csv('CLEANED_DATASET_20250520_135803.csv', parse_dates=['Date'])\n",
    "    df['year'] = df['Date'].dt.year\n",
    "\n",
    "    # 2a) Normalize all target variants before n-gram extraction\n",
    "    df = normalize_variants(df)\n",
    "\n",
    "    # 3) Build yearly n-gram table\n",
    "    results = []\n",
    "    for year, sub in df.groupby('year'):\n",
    "        if len(sub) < 5:\n",
    "            continue\n",
    "        ngr = extract_year_ngrams(sub, custom_stops, n_range=(1, 3), min_df=2, top_n=200)\n",
    "        ngr['year'] = year\n",
    "        ngr['tweet_count'] = len(sub)\n",
    "        ngr['freq_per_100_tweets'] = 100 * ngr['frequency'] / len(sub)\n",
    "        ngr['word_count'] = ngr['ngram'].str.split().apply(len)\n",
    "        results.append(ngr)\n",
    "\n",
    "    all_ngrams = pd.concat(results, ignore_index=True)\n",
    "    #all_ngrams.to_csv('yearly_ngram_frequencies.csv', index=False)\n",
    "\n",
    "    # 4) Find top trending terms\n",
    "    trending = find_trending_terms(all_ngrams, min_years=2, top_n=1000)\n",
    "    trending.to_csv('trending_terms.csv', index=False)\n",
    "\n",
    "    # 5) Print results\n",
    "    print(\"Top trending terms:\")\n",
    "    for _, r in trending.iterrows():\n",
    "        print(f\"{r.term}: {r.rel_change:.2f}× growth \"\n",
    "              f\"({r.first_freq:.2f}→{r.last_freq:.2f} per 100 tweets \"\n",
    "              f\"{r.first_year}→{r.last_year})\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34e7b6-9232-42f2-afc3-a1c8ded5ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "am_sma_data_cleaning",
   "language": "python",
   "name": "am_sma_data_cleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
