{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6aa964-de1f-4948-81ef-b41f26795f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a7b50-5d8e-481a-bfad-f7c6bc2798f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_per_year = pd.read_csv(\"random_sample_cleaned_dataset_20250520_144016.csv\")\n",
    "sampled_per_year['Date'] = pd.to_datetime(sampled_per_year['Date'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ad7234-5ca3-4a50-ba90-d814f5849c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233142/2345124950.py:10: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6c64732dcb478eae46222eb6b79ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50043f2df8614dfc8680a17a78389ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347ac12dd03448a2a373422e17ea27d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a3aeeb3684cc387e3d4dd3051cc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e96372ef1a24e99be1412dbfa53aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e08317d647464cbb47f73da80c169a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73fd9a22ee04a20b38e726652263d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running NER:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  total_entity_mentions\n",
      "0  2014                      1\n",
      "1  2020                      2\n",
      "2  2021                      1\n",
      "   year entity_text  count\n",
      "0  2014          at      1\n",
      "1  2020       ##ish      1\n",
      "2  2020          um      1\n",
      "3  2021          al      1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Assume `sampled_per_year` is your existing DataFrame\n",
    "df = sampled_per_year.copy()\n",
    "\n",
    "# 1. Ensure your Date column is datetime and extract year\n",
    "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# 2. Initialize the NER pipeline\n",
    "MODEL = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model     = AutoModelForTokenClassification.from_pretrained(MODEL)\n",
    "ner_pipe  = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    batch_size=64,\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# 3. Define a simple chunker to avoid OOM on millions of rows\n",
    "def chunker(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        batch = []\n",
    "        try:\n",
    "            for _ in range(size):\n",
    "                batch.append(next(it))\n",
    "        except StopIteration:\n",
    "            if batch:\n",
    "                yield batch\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "# 4. Run NER in chunks with a progress bar and collect results\n",
    "all_texts   = df['Normalized Text'].tolist()\n",
    "batch_size  = 500\n",
    "n_batches   = math.ceil(len(all_texts) / batch_size)\n",
    "all_entities = []\n",
    "\n",
    "for batch in tqdm(chunker(all_texts, batch_size),\n",
    "                  total=n_batches,\n",
    "                  desc=\"Running NER\"):\n",
    "    ents = ner_pipe(batch)\n",
    "    all_entities.extend(ents)\n",
    "\n",
    "# 5. Attach the extracted entities back to the DataFrame\n",
    "df['entities'] = all_entities\n",
    "\n",
    "# 6. Explode entities so that each entity is its own row\n",
    "exploded = (\n",
    "    df\n",
    "    .explode('entities')\n",
    "    .dropna(subset=['entities'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 7. Pull out the pieces of each entity\n",
    "exploded['entity_text']  = exploded['entities'].apply(lambda e: e['word'])\n",
    "exploded['entity_type']  = exploded['entities'].apply(lambda e: e['entity_group'])\n",
    "exploded['entity_score'] = exploded['entities'].apply(lambda e: e['score'])\n",
    "\n",
    "# 8. Now group by year to get overall counts and top entities\n",
    "# 8a. Total entity mentions per year\n",
    "yearly_counts = (\n",
    "    exploded\n",
    "    .groupby('year')\n",
    "    .size()\n",
    "    .reset_index(name='total_entity_mentions')\n",
    ")\n",
    "\n",
    "# 8b. Top 10 entities per year\n",
    "top_entities = (\n",
    "    exploded\n",
    "    .groupby(['year','entity_text'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(['year','count'], ascending=[True, False])\n",
    "    .groupby('year')\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# 9. Inspect results\n",
    "print(yearly_counts)\n",
    "print(top_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d9b769-0b7a-4f5b-8767-2b3b5a0e2e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>##ish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>um</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>al</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year entity_text  count\n",
       "0  2014          at      1\n",
       "1  2020       ##ish      1\n",
       "2  2020          um      1\n",
       "3  2021          al      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ae05fe-85fe-4e82-8509-33d53fe79f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Total Engagement</th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>row_num</th>\n",
       "      <th>Normalized Text</th>\n",
       "      <th>langdetect_is_english</th>\n",
       "      <th>Year</th>\n",
       "      <th>year</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@donttrythis</td>\n",
       "      <td>207</td>\n",
       "      <td>2012-11-14 18:57:16+00:00</td>\n",
       "      <td>@donttrythis_2012-11-14 18:57:16+00:00</td>\n",
       "      <td>42639</td>\n",
       "      <td>yay! my makerbot replicator 2 is packed, shipp...</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@themarginalian</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-06-02 17:00:50+00:00</td>\n",
       "      <td>@themarginalian_2012-06-02 17:00:50+00:00</td>\n",
       "      <td>150412</td>\n",
       "      <td>ooh! mit alums nervous system's gorgeous  3d-p...</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@EFF</td>\n",
       "      <td>64</td>\n",
       "      <td>2012-12-14 19:51:11+00:00</td>\n",
       "      <td>@EFF_2012-12-14 19:51:11+00:00</td>\n",
       "      <td>10264</td>\n",
       "      <td>. @eff  is targeting dangerous  3d printing  p...</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@paleofuture</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-08-02 03:44:33+00:00</td>\n",
       "      <td>@paleofuture_2012-08-02 03:44:33+00:00</td>\n",
       "      <td>119345</td>\n",
       "      <td>a  3d printer  that only prints 3d printers</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@medialab</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-15 20:20:19+00:00</td>\n",
       "      <td>@medialab_2012-08-15 20:20:19+00:00</td>\n",
       "      <td>105660</td>\n",
       "      <td>another look at neri oxman’s incredible  #3d  ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>@HashinJohnson</td>\n",
       "      <td>128</td>\n",
       "      <td>2023-01-16 00:50:32+00:00</td>\n",
       "      <td>@HashinJohnson_2023-01-16T00:50:32.000Z</td>\n",
       "      <td>6347230</td>\n",
       "      <td>tested my hash bucket s9 immersion cooled spac...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>@ravinash_kk</td>\n",
       "      <td>57</td>\n",
       "      <td>2023-12-05 19:34:52+00:00</td>\n",
       "      <td>@ravinash_kk_2023-12-05T19:34:52.000Z</td>\n",
       "      <td>6356457</td>\n",
       "      <td>1x pdra &amp; 1 x phd position available  @imperia...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>@loyalmoses</td>\n",
       "      <td>76</td>\n",
       "      <td>2023-10-07 20:14:34+00:00</td>\n",
       "      <td>@loyalmoses_2023-10-07T20:14:34.000Z</td>\n",
       "      <td>6381695</td>\n",
       "      <td>3d printer  companies that are the last to inc...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>@dddpworld</td>\n",
       "      <td>33</td>\n",
       "      <td>2023-02-06 12:14:21+00:00</td>\n",
       "      <td>@dddpworld_2023-02-06T12:14:21.000Z</td>\n",
       "      <td>6394435</td>\n",
       "      <td>the impossible gear fidget on  @thangs3d . thi...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@EJuskewitz</td>\n",
       "      <td>36</td>\n",
       "      <td>2023-11-09 13:43:54+00:00</td>\n",
       "      <td>@EJuskewitz_2023-11-09T13:43:54.000Z</td>\n",
       "      <td>6291757</td>\n",
       "      <td>dear hive mind, what  3d-printed  lab equipmen...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID  Total Engagement                      Date  \\\n",
       "0       @donttrythis               207 2012-11-14 18:57:16+00:00   \n",
       "1    @themarginalian                21 2012-06-02 17:00:50+00:00   \n",
       "2               @EFF                64 2012-12-14 19:51:11+00:00   \n",
       "3       @paleofuture                21 2012-08-02 03:44:33+00:00   \n",
       "4          @medialab                23 2012-08-15 20:20:19+00:00   \n",
       "..               ...               ...                       ...   \n",
       "115   @HashinJohnson               128 2023-01-16 00:50:32+00:00   \n",
       "116     @ravinash_kk                57 2023-12-05 19:34:52+00:00   \n",
       "117      @loyalmoses                76 2023-10-07 20:14:34+00:00   \n",
       "118       @dddpworld                33 2023-02-06 12:14:21+00:00   \n",
       "119      @EJuskewitz                36 2023-11-09 13:43:54+00:00   \n",
       "\n",
       "                                      tweet_id  row_num  \\\n",
       "0       @donttrythis_2012-11-14 18:57:16+00:00    42639   \n",
       "1    @themarginalian_2012-06-02 17:00:50+00:00   150412   \n",
       "2               @EFF_2012-12-14 19:51:11+00:00    10264   \n",
       "3       @paleofuture_2012-08-02 03:44:33+00:00   119345   \n",
       "4          @medialab_2012-08-15 20:20:19+00:00   105660   \n",
       "..                                         ...      ...   \n",
       "115    @HashinJohnson_2023-01-16T00:50:32.000Z  6347230   \n",
       "116      @ravinash_kk_2023-12-05T19:34:52.000Z  6356457   \n",
       "117       @loyalmoses_2023-10-07T20:14:34.000Z  6381695   \n",
       "118        @dddpworld_2023-02-06T12:14:21.000Z  6394435   \n",
       "119       @EJuskewitz_2023-11-09T13:43:54.000Z  6291757   \n",
       "\n",
       "                                       Normalized Text  langdetect_is_english  \\\n",
       "0    yay! my makerbot replicator 2 is packed, shipp...                   True   \n",
       "1    ooh! mit alums nervous system's gorgeous  3d-p...                   True   \n",
       "2    . @eff  is targeting dangerous  3d printing  p...                   True   \n",
       "3          a  3d printer  that only prints 3d printers                   True   \n",
       "4    another look at neri oxman’s incredible  #3d  ...                   True   \n",
       "..                                                 ...                    ...   \n",
       "115  tested my hash bucket s9 immersion cooled spac...                   True   \n",
       "116  1x pdra & 1 x phd position available  @imperia...                   True   \n",
       "117  3d printer  companies that are the last to inc...                   True   \n",
       "118  the impossible gear fidget on  @thangs3d . thi...                   True   \n",
       "119  dear hive mind, what  3d-printed  lab equipmen...                   True   \n",
       "\n",
       "     Year  year entities  \n",
       "0    2012  2012       []  \n",
       "1    2012  2012       []  \n",
       "2    2012  2012       []  \n",
       "3    2012  2012       []  \n",
       "4    2012  2012       []  \n",
       "..    ...   ...      ...  \n",
       "115  2023  2023       []  \n",
       "116  2023  2023       []  \n",
       "117  2023  2023       []  \n",
       "118  2023  2023       []  \n",
       "119  2023  2023       []  \n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4b9d1f-e892-41c8-ac6d-e188ec163646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Total Engagement</th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>row_num</th>\n",
       "      <th>Normalized Text</th>\n",
       "      <th>langdetect_is_english</th>\n",
       "      <th>Year</th>\n",
       "      <th>year</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@kosikyou2</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-09 16:24:39+00:00</td>\n",
       "      <td>@kosikyou2_2014-11-09T16:24:39.000Z</td>\n",
       "      <td>5280046</td>\n",
       "      <td>atlanta hawks logo wood pattern  3d printed  iphone 6 plus case  nta-hawks-logo-wood-pattern-3d-printed-iphone-6-plus-case.html ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>[{'entity_group': 'ORG', 'score': 0.6056939, 'word': 'at', 'start': 0, 'end': 2}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>@AUSTNigeria</td>\n",
       "      <td>62</td>\n",
       "      <td>2020-05-04 16:15:35+00:00</td>\n",
       "      <td>@AUSTNigeria_2020-05-04T16:15:35.000Z</td>\n",
       "      <td>493450</td>\n",
       "      <td>earlier today: \\n\\nthe materials science and engineering department, donated  3d-printed  reusable medical face shields to dr. aisha umar; director of clinical services &amp; c-mac, national hospital, abuja.</td>\n",
       "      <td>True</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'entity_group': 'PER', 'score': 0.9735368, 'word': '##ish', 'start': 126, 'end': 129}, {'entity_group': 'PER', 'score': 0.6936282, 'word': 'um', 'start': 131, 'end': 133}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>@dangerousladies</td>\n",
       "      <td>79</td>\n",
       "      <td>2021-10-27 17:13:09+00:00</td>\n",
       "      <td>@dangerousladies_2021-10-27T17:13:09.000Z</td>\n",
       "      <td>3021625</td>\n",
       "      <td>3d print  files for alisaie and alphinaud's ponytail holders from final fantasy xiv! comes in wholes and halves for easy printing.  9705845/alisaie-and-alphinaud-leveilleurs ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'entity_group': 'PER', 'score': 0.9227886, 'word': 'al', 'start': 32, 'end': 34}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID  Total Engagement                      Date  \\\n",
       "22        @kosikyou2                60 2014-11-09 16:24:39+00:00   \n",
       "89      @AUSTNigeria                62 2020-05-04 16:15:35+00:00   \n",
       "92  @dangerousladies                79 2021-10-27 17:13:09+00:00   \n",
       "\n",
       "                                     tweet_id  row_num  \\\n",
       "22        @kosikyou2_2014-11-09T16:24:39.000Z  5280046   \n",
       "89      @AUSTNigeria_2020-05-04T16:15:35.000Z   493450   \n",
       "92  @dangerousladies_2021-10-27T17:13:09.000Z  3021625   \n",
       "\n",
       "                                                                                                                                                                                                Normalized Text  \\\n",
       "22                                                                          atlanta hawks logo wood pattern  3d printed  iphone 6 plus case  nta-hawks-logo-wood-pattern-3d-printed-iphone-6-plus-case.html ...   \n",
       "89  earlier today: \\n\\nthe materials science and engineering department, donated  3d-printed  reusable medical face shields to dr. aisha umar; director of clinical services & c-mac, national hospital, abuja.   \n",
       "92                            3d print  files for alisaie and alphinaud's ponytail holders from final fantasy xiv! comes in wholes and halves for easy printing.  9705845/alisaie-and-alphinaud-leveilleurs ...   \n",
       "\n",
       "    langdetect_is_english  Year  year  \\\n",
       "22                   True  2014  2014   \n",
       "89                   True  2020  2020   \n",
       "92                   True  2021  2021   \n",
       "\n",
       "                                                                                                                                                                         entities  \n",
       "22                                                                                              [{'entity_group': 'ORG', 'score': 0.6056939, 'word': 'at', 'start': 0, 'end': 2}]  \n",
       "89  [{'entity_group': 'PER', 'score': 0.9735368, 'word': '##ish', 'start': 126, 'end': 129}, {'entity_group': 'PER', 'score': 0.6936282, 'word': 'um', 'start': 131, 'end': 133}]  \n",
       "92                                                                                            [{'entity_group': 'PER', 'score': 0.9227886, 'word': 'al', 'start': 32, 'end': 34}]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# 1. Ensure pandas will show full contents\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 2. Filter to rows where the 'entities' list is non-empty\n",
    "df_nonnull = df[df['entities'].apply(lambda ents: bool(ents))]\n",
    "\n",
    "# 3a. Simply print the DataFrame (full rows, full colwidth)\n",
    "df_nonnull\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6278d-acf5-4eae-9013-75c0cb4c9496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "am_sma_data_cleaning",
   "language": "python",
   "name": "am_sma_data_cleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
